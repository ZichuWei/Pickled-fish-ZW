---
title: "Assignment2"
author: "Zichu Wei u7457435"
date: "2022/10/29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Provide the link about my GitHub Repo 

[My GitHub Repository](https://github.com/ZichuWei/Pickled-fish-ZW)


## Statistical Analysis and Interpretation

### Load the necessary R Packages:

```{r,results='hide'}
# Data processing:
library(tidyverse)
library(readr)
library(dplyr)
library(plotrix)
```

```{r}
# Meta_analysis:
library(pacman)
pacman::p_load(metafor, orchaRd)
p_load(bookdown, devtools, tidyverse, ggforce, GGally, flextable, latex2exp, png,
    magick, metafor, MASS, emmeans, R.rsp)
devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
```

```{r}
# Draw the figures:
library(ggplot2)
```


### Read the files:

```{r}
# These analyses need these three files.
data <- read.csv("OA_activitydat_20190302_BIOL3207.csv")
paper <- read.csv("clark_paper_data.csv")
meta <- read.csv("ocean_meta_data.csv")
```

### Process and clean the original data:

```{r}
# Drop irrelevant columns 'loc' and 'comment':
data_clean <- subset(data,select = -c(loc, comment))
# Remove the missing data, which reflected by 'NA';
# Remove the incorrect data: some data cannot less than 0, so use filter to check and correct the data.
data_eff <- data_clean %>% filter(!is.na(activity)) %>% filter(animal_id > 0, activity > 0)
data_eff
```

```{r}
# Check spelling in species and treatment:
data_eff$species %>% unique()
data_eff$treatment %>% unique()
```

```{r}
# Because we find that there are six species and two treatments which are all correct, so we don't need to change or remove some data.
```


### 1. Summary statistics:

```{r}
# Because the following analyses need to analyze different treatment, so use 'filter' to separate the treatment:
data_ctrl <- data_eff %>% filter(treatment=="control")
data_oa <- data_eff %>% filter(treatment=="CO2")
```

#### Gnerate the summary staistics for different levels:

Use 'group_by' and 'summarize' to generate the summary statistics (means, SD, N) for each fish species' average activity for each treatment.

```{r}
# Control: According to the column name in the 'meta-data_ocean_meta.csv' file, set the column as 'ctrl.mean', 'ctrl.sd', 'ctrl.n':
data1 <- data_ctrl %>% group_by(species) %>% summarize(ctrl.mean = mean(activity), ctrl.sd = sd(activity), ctrl.n = length(species))
data1
```

```{r}
# CO2: According to the column name in the 'meta-data_ocean_meta.csv' file, set the column as 'oa.mean', 'oa.sd', 'oa.n':
data2 <- data_oa %>% group_by(species) %>% summarize(oa.mean = mean(activity), oa.sd = sd(activity), oa.n = length(species))
data2
```

```{r}
# Merge the summary statistics for the following processing:
data_1 <- merge(data1,data2)
data_1
```


### 2-3. Merge summary statistics with the metadata:

#### 2. Metadata in 'clark_paper_data.csv' file:

Merge the summary statistics generated from the above with the metadata in 'clark_paper_data.csv' file:

```{r}
# Use 'merge' function to merge 'data_1' with 'paper', let the sequence as 'paper' in the left.
data_2 <- merge(paper,data_1)
data_2
```

#### 3. Metadata in 'ocean_meta_data.csv' file:

Merge the combined summary statistics 'data_1' and metadata from Clark et al. 'paper' (output 'data_2') into the larger meta-analysis dataset 'ocean_meta_data.csv' file:

```{r}
# Use 'rbind()' function to merge 'data_2' with 'meta':
# We can find that 'meta' and 'data_2' have different colnames, and both have very informal colnames, so we can use 'janitor::clean_names()' to polish them:
data_3 <- rbind(meta %>% janitor::clean_names(),data_2 %>% janitor::clean_names())
data_3$residual <- 1:dim(data_3)[1]
# We find 'oa_mean' and 'oa_sd' both have some NA values, in order to help the following analysis, then we first remove them.
data_4 <- data_3 %>% filter(!is.na(oa_mean)) %>% filter(!is.na(oa_sd))
summary(data_4)
```



### 4. Calculate lnRR effect size:

Correctly calculate the log response ratio (lnRR) effect size for every row of the dataframe using metafor’s 'escalc()' function

```{r}
# Avoid NA values, we choose the value greater than 0:
data_complete <- data_4 %>% filter(ctrl_mean>0,ctrl_n>0,ctrl_sd>0,oa_n>0,oa_mean>0,oa_sd>0)
data_lnRR <- escalc(measure="ROM", m1i=ctrl_mean, m2i=oa_mean, sd1i=ctrl_sd, sd2i=oa_sd, n1i=ctrl_n, n2i=oa_n,data=data_complete)
str(data_lnRR)
# 'yi' means the value of 'lnRR' effect size.
```


### 5. Controls for the sampling variance of lnRR:

Correct meta-analytic model fitted to the data that controls for the sampling variance of lnRR. The model should include a random effect of study and observation. Use metafor’s 'rma.mv()' function.

```{r}
# Random effect analysis:
data_v1 <- rma.mv(yi, vi, test = "t", dfs = "contain", data = data_lnRR)
summary(data_v1)
```

```{r}
# Multiple-level meta-analytic model:
# Estimate a random effect variance for between study (i.e., study) and within-study (i.e., residual) grouping variables to control for non-independence and understand sources driving effect size variability.
data_v <- metafor::rma.mv(yi, vi, 
                   method="REML",
                   random=list(~1|study,
                               ~1|residual), 
                   dfs = "contain",
                   test="t",
                   data=data_lnRR)
summary(data_v)
```

```{r}
# The explanation of the above code is below.
```


### 6. Written paragraph:

Written paragraph of the findings and what they mean which is supported with a figure. The paragraph should include:

#### 1) Overall meta-analytic mean & Uncertainty in the overall meta-analytic mean:

Correct presentation and interpretation of overall meta-analytic mean and measures of uncertainty around the mean estimate (e.g., 95% confidence intervals).

```{r}
# Overall meta-analytic mean:
# From the model by extracting the intercept (labeled ‘estimate’ in the model output), we can know what the overall meta-analytic mean effect size across the studies actually is estimated to be. And the model is just an object that stores all the values for us.
# We can extract the estimate using the 'coef' function, it is estimated to be -0.1497, which tells us that the mean 'yi' value is negative, and there is a rather weak overall association between physiology and dispersal / movement when we pool across all studies.
```

```{r}
# Use transformation 'rma': convert the overall meta-analytic mean back to the correlation coefficient.
predict(data_v, transf = "transf.rma")
```

```{r}
# Uncertainty in the overall meta-analytic mean:
# 95% confidence intervals are important to provide and they are stored in the data_v object as ci.lb and ci.up. We can extract the 95% confidence intervals in the table which range from -0.3810 to 0.0817, that is, 95% of the time we would expect the true mean to fall between 'yi' values of -0.3810 to 0.0817. And if we were to repeat the experiment many times, 95% of the confidence intervals constructed would contain the true meta-analytic mean.
```
 
```{r} 
# Testing the hypothesis about whether the overall meta-analytic mean is different from 0.
# We can also see that the null hypothesis that yi = 0 can be rejected because there is a significantly smaller estimate than a correlation of 0, which we can see from the p-value being < 0.05. To be more exact, the p-value is < 0.0001.
```


#### 2) Measures of heterogeneity in effect size estimates:

Measures of heterogeneity in effect size estimates across studies (i.e., I2 and/or prediction intervals - see 'predict()' function in 'metafor')

```{r, het, tab.cap = "Total effect size hetereogneity (Total), as well as the proportion of hetereogeneity in effects resulting from Study and Residual / Observational" }
# I2 measurement:
# Calculate I2:
i2_vals <- orchaRd::i2_ml(data_v)

# Clean up the names of the different I2 estimates and use some regular expressions to fix that. 'gsub()' function is used for replacement operations, change the original 'I2_' to blank. And use 'firstup()' to make the first letter of what is left 'type' capitalised.
i2 <- tibble(type = firstup(gsub("I2_", "", names(i2_vals))), I2 = i2_vals)

# Use 'flextable' to make a pretty table.
flextable(i2) %>%
    align(part = "header", align = "center") %>%
    compose(part = "header", j = 1, value = as_paragraph(as_b("Type"))) %>%
    compose(part = "header", j = 2, value = as_paragraph(as_b("I"), as_b(as_sup("2")),
        as_b("(%)"))) %>% autofit(add_h = 0.5, part = c("body", "header"))
```

```{r}
# According to the I2 of total, we can conclude that we have highly heterogeneous effect size data because sampling variation.
# From the multi-level meta-analytic model we find that only 10% of the total variation in effect size estimates is the result of differences between studies.
```


```{r}
# Prediction intervals measurement:
predict(data_v)
```

```{r}
# The prediction intervals are labelled 'pi.lb' (lower bound) and 'pi.ub' (upper bound), in this model, the prediction intervals are range from -4.4483 to 4.1490. It means 95% prediction intervals are wide. Effect sizes (yi) are expected to range from -4.4483 to 4.1490 95% of the time with repeated experiments, suggesting a lot of inconsistency between studies.
```


#### 3) Forest plot:

Forest plot showing the mean estimate, 95% confidence interval, and prediction interval with clearly labelled axes, number of samples and studies plotted on figure.

```{r rochard, fig.cap= "Orchard plot showing the correlation coefficients estimated in the intrcpt. k = the number of effect sizes and the number of studies are in brackets. The size of the effect is scaled by the precision of each effect size value, which is 1 / sqrt(vir)"}
# Make an orchard plot using the model object, and the orchard plot improved from the forest plot.
orchaRd::orchard_plot(data_v, mod = "1", group = "study", data = data_lnRR,
    xlab = "Correlation Coefficient", angle = 45)
```

```{r}
# The orchard plot as a variant on the classic forest plot, cultivated to the needs of meta‐analysts in ecology and evolution, showing the mean for correlation coefficients estimated between physiology and activity, dispersal and behavior. k = the number of effect sizes 757 (the number of studies = 91). The size of the effect is scaled by the precision of each effect size value, there are more numbers in the middle distribution, which is less accurate.
```




